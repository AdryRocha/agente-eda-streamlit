# app.py (Vers√£o Final Unificada para Execu√ß√£o Local e Deploy na Nuvem)

import streamlit as st
import pandas as pd
import os
import re
import traceback
from agent_core import create_eda_agent

st.set_page_config(page_title="Agente Aut√¥nomo de EDA", page_icon="ü§ñ", layout="wide")
st.title("ü§ñ Agente Aut√¥nomo para An√°lise Explorat√≥ria de Dados (EDA)")
st.caption("Fa√ßa upload de um arquivo CSV e converse com seus dados em linguagem natural.")

def extract_filepath(text: str):
    """Extrai o caminho de um arquivo de imagem da resposta do agente."""
    pattern = r"(plots/[a-zA-Z0-9_.\-]+\.png)"
    match = re.search(pattern, text)
    return match.group(1) if match else None

# --- Gerenciamento Inteligente de API Key ---
# Tenta ler a chave dos "Secrets" do Streamlit Cloud primeiro.
# Se n√£o encontrar, assume que estamos em um ambiente local.
api_key_from_secrets = None
try:
    # Acessa a chave espec√≠fica dentro do objeto st.secrets
    api_key_from_secrets = st.secrets.get("GEMINI_API_KEY")
except (AttributeError, KeyError):
    # Isso √© esperado em um ambiente local sem um arquivo secrets.toml
    pass

# Inicializa o estado da sess√£o
if "messages" not in st.session_state:
    st.session_state.messages = []
if "agent_executor" not in st.session_state:
    st.session_state.agent_executor = None
if "dataframe" not in st.session_state:
    st.session_state.dataframe = None

# --- Barra Lateral (Sidebar) ---
with st.sidebar:
    st.header("1. Configura√ß√£o do Modelo")

    # Se a chave de API foi encontrada nos segredos, for√ßa o uso do Gemini (cen√°rio de deploy).
    # Caso contr√°rio, mostra o seletor para o usu√°rio (cen√°rio local).
    if api_key_from_secrets:
        model_provider = "Google Gemini (API, Gratuito com Chave)"
        st.info("Aplica√ß√£o configurada para usar Google Gemini via API segura.")
        api_key = api_key_from_secrets
    else:
        model_provider = st.radio(
            "Escolha o modelo de linguagem:",
            ("Ollama (Local, 100% Gratuito)", "Google Gemini (API, Gratuito com Chave)")
        )
        api_key = None
        if "Gemini" in model_provider:
            api_key = st.text_input(
                "Insira sua Chave de API do Google AI Studio:",
                type="password",
                key="google_api_key"
            )
            st.caption("Obtenha sua chave gratuita em [aistudio.google.com](https://aistudio.google.com/app/apikey)")

    st.header("2. Carregue seus Dados")
    uploaded_file = st.file_uploader("Carregue seu arquivo CSV", type="csv")

    if uploaded_file is not None:
        if st.button("Iniciar An√°lise"):
            # Valida√ß√£o robusta da chave de API
            final_api_key = api_key
            if "Gemini" in model_provider and (not final_api_key or final_api_key.strip() == ""):
                st.error("‚ö†Ô∏è Por favor, insira sua chave de API do Google para usar o Gemini.")
            else:
                with st.spinner("Carregando dados e inicializando o agente..."):
                    try:
                        df = pd.read_csv(uploaded_file)
                        st.session_state.dataframe = df

                        # Garante que a chave seja passada como uma string limpa
                        clean_api_key = final_api_key.strip() if final_api_key else None

                        st.session_state.agent_executor = create_eda_agent(
                            df,
                            model_provider,
                            clean_api_key
                        )

                        st.session_state.messages = [
                            {"role": "assistant", "content": f"‚úÖ Agente inicializado com {model_provider}. Estou pronto para analisar!"}
                        ]
                        st.success("üéâ Agente pronto!")
                    except Exception as e:
                        st.error(f"‚ùå Ocorreu um erro na inicializa√ß√£o: {e}")
                        st.code(traceback.format_exc())

    if st.session_state.dataframe is not None:
        st.markdown("### üìä Preview dos Dados")
        st.dataframe(st.session_state.dataframe.head())

# --- Interface de Chat Principal ---
for message in st.session_state.messages:
    with st.chat_message(message["role"]):
        filepath = extract_filepath(message["content"])
        if filepath and os.path.exists(filepath):
            clean_content = re.sub(r"\s*e salvo em:.*\.png", "", message["content"])
            st.markdown(clean_content)
            st.image(filepath)
        else:
            st.markdown(message["content"])

if prompt := st.chat_input("Fa√ßa uma pergunta sobre seus dados..."):
    st.session_state.messages.append({"role": "user", "content": prompt})
    with st.chat_message("user"):
        st.markdown(prompt)

    if st.session_state.agent_executor is None:
        st.warning("‚ö†Ô∏è Por favor, carregue um arquivo CSV e clique em 'Iniciar An√°lise'.")
    else:
        with st.chat_message("assistant"):
            with st.spinner("ü§î Pensando..."):
                try:
                    response = st.session_state.agent_executor.invoke({"input": prompt})
                    response_content = response['output']
                    st.session_state.messages.append({"role": "assistant", "content": response_content})

                    filepath = extract_filepath(response_content)
                    if filepath and os.path.exists(filepath):
                        clean_content = re.sub(r"\s*e salvo em:.*\.png", "", response_content)
                        st.markdown(clean_content)
                        st.image(filepath)
                    else:
                        st.markdown(response_content)
                except Exception as e:
                    error_message = f"‚ùå Ocorreu um erro durante a execu√ß√£o: {e}"
                    st.error(error_message)
                    st.code(traceback.format_exc())
                    st.session_state.messages.append({"role": "assistant", "content": error_message})
